# API
API_HOST=0.0.0.0
API_PORT=8000

VECTOR_STORAGE_DIR=./storage
VECTOR_QUERY_HISTORY_DB=query_history.db

# Embedding
EMBEDDING_CHUNK_SIZE=500
# Smaller & faster
#EMBEDDING_MODEL=paraphrase-MiniLM-L3-v2
# Balanced (default)
EMBEDDING_MODEL=multi-qa-distilbert-cos-v1
# More accurate but slower
#EMBEDDING_MODEL=all-mpnet-base-v2

# LLM
LLM_MODEL_PATH_OR_REPO_ID=TheBloke/Llama-2-7B-Chat-GGUF
LLM_MODEL_TYPE=llama
LLM_MODEL_FILE=llama-2-7b-chat.Q4_K_M.gguf
LLM_MODEL_CONTEXT_LENGTH=8192
LLM_MODEL_GPU_LAYERS=8
LLM_MODEL_CPU_THREADS=8

LLM_MODEL_MAX_NEW_TOKENS=1024
LLM_MODEL_TEMPERATURE=0.5
LLM_MODEL_TOP_P=0.95
LLM_MODEL_BEHAVIOUR_CONTEXT="Based on the following context, answer the question. If the context doesn't contain relevant information, just respond that you could not find anything related."

LLM_CACHE_DIR=./.cache

# HUGGINGFACE
HF_HOME=./.cache/huggingface
HF_TOKEN=
